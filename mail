Got it ✅ — you basically want a Jenkins fetch pipeline that:

1. Runs bsla and reads lsb.resources.


2. Parses both to get:

SLA Name

SLA Guaranteed

SLA Used

Total Used SLA

SLA % from lsb.resources



3. Queries Oracle DB for each SLA to get last_modified_by and timestamp.


4. Returns merged JSON to the Flask backend, which sends it to the frontend.




---

Jenkins Fetch SLA Pipeline (sla_fetch_pipeline.groovy)

pipeline {
    agent any
    parameters {
        string(name: 'cluster_name', defaultValue: '', description: 'Cluster name')
    }
    stages {
        stage('Fetch SLA Data') {
            steps {
                script {
                    // 1. Run bsla and capture output
                    def bslaOutput = sh(script: "bsla -m ${params.cluster_name}", returnStdout: true).trim()

                    // 2. Read lsb.resources file
                    def lsbFilePath = "/path/to/lsb.resources"
                    def lsbContent = readFile(lsbFilePath)

                    // 3. Parse bsla output
                    def slaData = []
                    def currentSLA = [:]
                    bslaOutput.split("\\n").each { line ->
                        if (line.startsWith("SERVICE CLASS NAME:")) {
                            if (currentSLA) slaData << currentSLA
                            currentSLA = [sla_name: line.split(":")[1].trim()]
                        }
                        else if (line.contains("GUARANTEE") && line.contains("POOL NAME") == false) {
                            // Skip header lines
                        }
                        else if (line.trim().startsWith("TI_SLA_pool")) {
                            def parts = line.trim().split("\\s+")
                            currentSLA.guaranteed = parts[2]
                            currentSLA.used = parts[3]
                            currentSLA.total_used = parts[4]
                        }
                    }
                    if (currentSLA) slaData << currentSLA

                    // 4. Parse SLA percentage from lsb.resources
                    def percentPattern = /\[(\w+),\s*([0-9]+)%\]/
                    def slaPercentMap = [:]
                    (lsbContent =~ percentPattern).each { match ->
                        slaPercentMap[match[1]] = match[2]
                    }
                    slaData.each { sla ->
                        sla.sla_percent = slaPercentMap[sla.sla_name] ?: null
                    }

                    // 5. Get last modified info from Oracle DB
                    withCredentials([usernamePassword(credentialsId: 'oracle-db-creds', usernameVariable: 'DB_USER', passwordVariable: 'DB_PASS')]) {
                        def sqlQuery = """
                        SELECT sla_name, modified_by, TO_CHAR(timestamp, 'YYYY-MM-DD HH24:MI:SS') AS ts
                        FROM sla_changes
                        WHERE cluster_name='${params.cluster_name}'
                        AND sla_name = :slaName
                        ORDER BY timestamp DESC FETCH FIRST 1 ROWS ONLY
                        """

                        slaData.each { sla ->
                            def dbResult = sh(
                                script: """sqlplus -S $DB_USER/$DB_PASS@//oracle-host:1521/ORCLPDB1 <<EOF
                                    SET HEADING OFF FEEDBACK OFF VERIFY OFF
                                    ${sqlQuery.replace(":slaName", "'${sla.sla_name}'")}
                                    EXIT;
EOF""",
                                returnStdout: true
                            ).trim()

                            if (dbResult) {
                                def parts = dbResult.split("\\s+")
                                sla.last_modified_by = parts[0]
                                sla.last_modified_time = parts[1] + " " + parts[2]
                            } else {
                                sla.last_modified_by = null
                                sla.last_modified_time = null
                            }
                        }
                    }

                    // 6. Save as JSON for backend
                    def jsonFile = "/tmp/sla_data_${params.cluster_name}.json"
                    writeFile file: jsonFile, text: groovy.json.JsonOutput.toJson(slaData)

                    // 7. Send to backend API
                    sh """
                        curl -X POST http://flask-backend-url/api/sla/data \\
                        -H 'Content-Type: application/json' \\
                        -d @${jsonFile}
                    """
                }
            }
        }
    }
}


---

Changes Needed in Backend

We add a new endpoint /api/sla/data that receives the parsed SLA JSON from Jenkins and stores it temporarily in memory (or cache) so the frontend can retrieve it.

# In app.py
sla_cache = {}

@app.route('/api/sla/data', methods=['POST'])
def receive_sla_data():
    data = request.json
    cluster = request.args.get('cluster_name')
    sla_cache[cluster] = data
    return jsonify({"status": "data received"}), 200

@app.route('/api/sla/get', methods=['GET'])
def get_sla_data():
    cluster = request.args.get('cluster_name')
    return jsonify(sla_cache.get(cluster, []))


---

Flow

1. Frontend → /api/sla/fetch → triggers fetch pipeline in Jenkins.


2. Pipeline:

Runs bsla & parses

Reads lsb.resources & parses

Fetches DB audit info

Merges into JSON

POSTs to backend /api/sla/data



3. Frontend fetches from /api/sla/get to render in table.




---

If you want, I can now merge this fetch pipeline with your update pipeline so that both are in a single job or keep them separate for modularity.

Do you want me to merge or keep separate?

