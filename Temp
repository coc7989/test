import subprocess
import re
import json
from datetime import datetime

# Sample config file data
config = {
    "reg": {
        "priority_rating": 30,
        "current_slot_limit": 300,
        "new_slot_limit": 400,
        "run_time_limit": 20,  # in seconds
        "remainders": [8, 15, 19],
        "exceptions_allowed": "No",
        "access": "open",
        "purpose": "general purpose sims"
    },
    "normal": {
        "priority_rating": 50,
        "current_slot_limit": 20,
        "new_slot_limit": 40,
        "run_time_limit": 20,  # in seconds
        "remainders": [8, 15, 19],
        "exceptions_allowed": "No",
        "access": "open",
        "purpose": "Debug sims"
    }
}

# Run the bjobs command and fetch job data
def get_bjobs_output():
    command = "bjobs -u all -r -o 'delimiter=\",\" user jobid jobindex queue start_time run_time stat' | sort -g | grep -v gui"
    result = subprocess.run(command, shell=True, capture_output=True, text=True)
    return result.stdout.strip()

# Parse the output from the bjobs command
def parse_bjobs_output(bjobs_output):
    jobs = []
    for line in bjobs_output.splitlines():
        user, jobid, jobindex, queue, start_time, run_time, status = line.split(',')
        run_time_sec = int(re.search(r'\d+', run_time).group())
        jobs.append({
            "user": user,
            "jobid": jobid,
            "jobindex": jobindex,
            "queue": queue,
            "start_time": start_time,
            "run_time": run_time_sec,
            "status": status
        })
    return jobs

# Check if the job is expired or going to expire
def categorize_jobs(jobs):
    already_expired_job_ids = []
    going_to_expire_job_ids = []

    for job in jobs:
        queue_name = job['queue']
        run_time_limit = config[queue_name]['run_time_limit']
        remainders = config[queue_name]['remainders']

        if job['run_time'] >= run_time_limit:
            already_expired_job_ids.append(job)
        elif any(job['run_time'] >= r for r in remainders):
            going_to_expire_job_ids.append(job)

    return already_expired_job_ids, going_to_expire_job_ids

# Generate final data to be emailed
def generate_email_data(jobs, expired=True):
    final_data = []
    for job in jobs:
        queue_name = job['queue']
        run_time_limit = config[queue_name]['run_time_limit']
        if expired and job['run_time'] >= run_time_limit:
            final_data.append(job)
        elif not expired:
            remainders = config[queue_name]['remainders']
            if any(job['run_time'] >= r for r in remainders):
                final_data.append(job)
    return final_data

# Group data by user
def group_by_user(jobs):
    user_data = {}
    for job in jobs:
        user = job['user']
        if user not in user_data:
            user_data[user] = []
        user_data[user].append(job)
    return user_data

# Send email (mocked function, replace with actual sending logic)
def send_email(user, data):
    print(f"Sending email to {user} with data: {data}")

# Log email activity
def log_email(user):
    with open("log.txt", "a") as log_file:
        log_file.write(f"{datetime.now()}: Sent email to {user}\n")

# Main logic
def main():
    bjobs_output = get_bjobs_output()
    jobs = parse_bjobs_output(bjobs_output)

    already_expired_job_ids, going_to_expire_job_ids = categorize_jobs(jobs)

    if already_expired_job_ids:
        final_already_expired_mail_data = generate_email_data(already_expired_job_ids, expired=True)
        grouped_expired_data = group_by_user(final_already_expired_mail_data)
        for user, data in grouped_expired_data.items():
            send_email(user, data)
            log_email(user)

    if going_to_expire_job_ids:
        final_going_to_expire_mail_data = generate_email_data(going_to_expire_job_ids, expired=False)
        grouped_expire_data = group_by_user(final_going_to_expire_mail_data)
        for user, data in grouped_expire_data.items():
            send_email(user, data)
            log_email(user)

if __name__ == "__main__":
    main()
