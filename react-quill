Thanks for the clarification â€” since your scheduled_database_removal_query() (and other backend logic) uses write_to_cron_log() and write_to_api_log(), youâ€™ll need to extend those functions to support dynamic log file paths based on the branch (i.e., dev, stage, or prod).

Right now, they write to files determined once using the environment variable when the server starts â€” that wonâ€™t work if you want different branches writing to different files dynamically.


---

âœ… What You Should Do

Update your logging functions to dynamically determine the log file path based on the current branch, similar to the get_log_filepath() function you already used for reading logs.


---

ðŸ” Step-by-step Code Changes

1. Update write_to_api_log() and write_to_cron_log() to accept an optional branch_name:

def write_to_cron_log(message, branch_name=None):
    filepath = get_log_filepath('cron', branch_name or os.getenv('BRANCH_NAME', 'dev'))
    write_to_file(filepath, message)

def write_to_api_log(message, branch_name=None):
    filepath = get_log_filepath('api', branch_name or os.getenv('BRANCH_NAME', 'dev'))
    write_to_file(filepath, message)

> If branch_name isn't provided explicitly, it falls back to the environment variable (BRANCH_NAME).




---

2. Your get_log_filepath() remains as described earlier:

def get_log_filepath(log_type, branch_name):
    filename_prefix = ''
    branch_name = branch_name.lower()

    if branch_name in ['dev', 'stage']:
        filename_prefix = f"{branch_name}_"

    if log_type == 'api':
        filename = f"{filename_prefix}api_errors.log"
    elif log_type == 'cron':
        filename = f"{filename_prefix}cron_jobs.log"
    else:
        return None

    return os.path.join(LOG_DIR, filename)


---

3. Your write_to_file() stays the same:

def write_to_file(filepath, message):
    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    with open(filepath, 'a') as f:
        f.write(f"[{timestamp}] {message}\n")


---

4. Your scheduled_database_removal_query() remains unchanged (unless you want to make it explicit):

def scheduled_database_removal_query():
    try:
        write_to_cron_log("Job started: daily_database_removal_query")
        print("some code ignore that..")

    except Exception as error:
        write_to_api_log(f"[scheduled_database_removal_query] Error: {str(error)}")
        write_to_cron_log(f"Failed with general error: {error}")

If you'd prefer to be more explicit, you could do:

write_to_cron_log("Job started", branch_name='stage')

But that's optional if your BRANCH_NAME environment variable is correct.


---

âœ… Final Notes

This setup ensures you write logs to the correct files dynamically â€” based on branch.

No need to hardcode filenames.

For prod, logs will go to api_errors.log and cron_jobs.log automatically (no prefix).


Let me know if you're using multiple branches in parallel (e.g., multi-tenancy) â€” that would require passing the branch name explicitly everywhere.

