rdef get_user_queue_limits(user_id, queue):
    blimits_out = run_cmd(f"blimits -a -u {user_id} | grep {queue}")
    used, quota = 0, -1
    for line in blimits_out.splitlines():
        slot_info = line.split()[-1]
        if '/' in slot_info:
            used_str, limit_str = slot_info.split('/')
            used = int(used_str) if used_str.isdigit() else 0
            quota = int(limit_str) if limit_str.isdigit() else -1
            break
    return used, quota


def should_move_job(job, user_quota_cache):
    user_id = job['user_id']
    queue = job['queue']
    pend_slots = job['pend_slots']

    if queue != 'normal':
        return False  # Only moving from 'normal'

    if is_job_already_moved(job['job_id']):
        return False

    normal_key = (user_id, 'normal')
    normal_used, normal_quota = user_quota_cache.get(normal_key, (0, -1))

    regress_key = (user_id, 'regress')
    regress_used, regress_quota = user_quota_cache.get(regress_key, (0, -1))

    if normal_quota == -1:
        normal_used, normal_quota = get_user_queue_limits(user_id, 'normal')
        user_quota_cache[normal_key] = (normal_used, normal_quota)

    if regress_quota == -1:
        regress_used, regress_quota = get_user_queue_limits(user_id, 'regress')
        user_quota_cache[regress_key] = (regress_used, regress_quota)

    # Decision logic
    if normal_used >= normal_quota and (regress_used + pend_slots) <= regress_quota:
        return True
    return False


def attempt_move_job(job, user_quota_cache):
    user_id = job['user_id']
    pend_slots = job['pend_slots']

    # Update queue before move
    job['original_queue'] = job['queue']
    job['queue'] = 'regress'

    move_job(job)
    record_job_move(
        job=job,
        score=0,
        reason="normal full, regress available",
        rules_applied=["normal_full_regress_has_capacity"],
        cycle_id="auto-cycle-001"
    )

    # Update cache
    key = (user_id, 'regress')
    current_used, quota = user_quota_cache.get(key, (0, -1))
    user_quota_cache[key] = (current_used + pend_slots, quota)


def parse_mbjobs2():
    queue_pattern = '|'.join(QUEUE)
    output = run_cmd(f"/db/lsf/work/local/bin/mbjobs2 | grep PEND | grep -E '{queue_pattern}' | awk -F',' '$NF > 300'")
    jobs = []
    user_quota_cache = {}

    for line in output.splitlines():
        fields = line.strip().split(',')
        if len(fields) < 24:
            continue

        queue = fields[14]
        if queue not in QUEUE:
            continue

        job = {
            'job_id': fields[0],
            'user_id': fields[2],
            'queue': queue,
            'pend_slots': int(fields[17]),
            'project': fields[18],
            'res_req': fields[15],
            'pend_time': int(fields[23]),
        }

        key = (job['user_id'], queue)
        if key not in user_quota_cache:
            user_quota_cache[key] = get_user_queue_limits(job['user_id'], queue)

        job['running'], job['quota'] = user_quota_cache[key]

        # Decide and act on move
        if should_move_job(job, user_quota_cache):
            attempt_move_job(job, user_quota_cache)
        else:
            jobs.append(job)

    return jobs
