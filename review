uGreat! Since you want a dynamic Jenkinsfile that behaves differently based on the branch (dev vs prod), you can use a single Jenkinsfile in both branches, and control the behavior based on the BRANCH_NAME variable provided by Jenkins.

This gives you the best of both worlds:

‚úÖ Same file in both branches (easy to maintain)

‚úÖ Different behavior based on which branch is being built



---

‚úÖ Final Dynamic Jenkinsfile for Both dev and prod

Put this exact Jenkinsfile in both the dev and prod branches:

pipeline {
    agent any

    environment {
        // Dynamically set environment mode based on branch name
        PYTHON_ENV = "${env.BRANCH_NAME == 'prod' ? 'prod' : 'dev'}"
    }

    triggers {
        // Only enable cron for prod branch
        when {
            branch 'prod'
        }
        cron('H/5 * * * *') // every 5 minutes (only applies to prod)
    }

    stages {
        stage('Run on All Nodes') {
            matrix {
                axes {
                    axis {
                        name 'NODE_LABEL'
                        values 'server1', 'server2', 'server3', 'server4'
                    }
                }
                agent { label NODE_LABEL }
                stages {
                    stage('Checkout & Run') {
                        steps {
                            echo "Running on branch: ${env.BRANCH_NAME}"
                            echo "Environment: ${PYTHON_ENV}"

                            sh '''
                            ENVIRONMENT=${PYTHON_ENV} python3 main.py
                            '''
                        }
                    }
                }
            }
        }
    }
}


---

‚úÖ What This Does

Feature	Behavior

PYTHON_ENV	Automatically set to prod or dev based on BRANCH_NAME
triggers {}	Runs every 5 minutes only if branch is prod
matrix	Executes on all 4 Jenkins nodes: server1 through server4
main.py	Uses ENVIRONMENT=dev or ENVIRONMENT=prod accordingly



---

‚úÖ How main.py Handles It

In main.py:

import os

ENVIRONMENT = os.getenv("ENVIRONMENT", "dev")
IS_DRY_RUN = ENVIRONMENT == "dev"

print(f"Running in {ENVIRONMENT.upper()} mode")

if IS_DRY_RUN:
    print(f"[DRY-RUN] Would move job {job['job_id']} to {target_queue}")
else:
    run_cmd(f"bmod -q {target_queue} {job['job_id']}")


---

‚úÖ Summary

Use this single dynamic Jenkinsfile in both dev and prod branches.

Jenkins figures out the branch and adjusts the environment and schedule accordingly.

Keeps your setup clean, maintainable, and dynamic.



---

Would you like me to generate a ready-to-paste Bitbucket repo file structure or help you set up the webhook for triggering dev on push?


Thanks for clarifying ‚Äî you're working in a production-only server environment, but want to simulate dev/prod separation logically within the same infrastructure. That's totally doable ‚Äî here's a clean and practical setup for you.


---

‚úÖ Your Goals Recap

1. Use Bitbucket dev and prod branches to separate logic.


2. All 4 servers are prod, but you want the script to behave differently based on the branch/environment.


3. Script runs via cron ‚Äî either OS-level or Jenkins-managed.


4. Script runs every 5 minutes.




---

‚úÖ Recommended Design

üí° Use Jenkins to Pull the Right Branch

Let Jenkins:

Pull from dev branch for dry-run mode.

Pull from prod branch for live execution.


üí° Simulate Dev/Prod in Code

Inside your script (main.py), use:

import os

ENVIRONMENT = os.getenv("ENVIRONMENT", "dev")  # default to dev

IS_DRY_RUN = ENVIRONMENT == "dev"

# Then use this flag in your logic
if IS_DRY_RUN:
    print(f"[DRY-RUN] Would move job {job['job_id']} to {target_queue}")
else:
    run_cmd(f"bmod -q {target_queue} {job['job_id']}")

‚úÖ Jenkins Cron (Best Option)

Use a Jenkins scheduled job instead of system cron because:

It logs everything (better audit/history).

It pulls the latest code automatically.

It scales across agents.

It's easier to manage changes and rollbacks.



---

‚úÖ Jenkins Setup: Dev & Prod Pipeline

üîß Jenkinsfile (Multi-Branch Aware)

Here's a smart Jenkinsfile you can use:

pipeline {
    agent any

    environment {
        PYTHON_ENV = "${env.BRANCH_NAME == 'prod' ? 'prod' : 'dev'}"
    }

    triggers {
        cron('H/5 * * * *')  // every 5 minutes
    }

    stages {
        stage('Checkout') {
            steps {
                checkout scm
            }
        }

        stage('Run Script on All Prod Nodes') {
            matrix {
                axes {
                    axis {
                        name 'NODE_LABEL'
                        values 'server1', 'server2', 'server3', 'server4'
                    }
                }
                agent { label NODE_LABEL }
                stages {
                    stage('Execute Script') {
                        steps {
                            sh '''
                            source venv/bin/activate || true
                            ENVIRONMENT=${PYTHON_ENV} python3 main.py
                            '''
                        }
                    }
                }
            }
        }
    }
}

> ‚úÖ This will:

Run every 5 mins

Use dev or prod behavior based on branch

Apply changes (or dry-run) depending on the environment





---

‚úÖ Bitbucket Branching Policy

dev branch = simulate moves (dry-run)

prod branch = actual job switching

Create PRs from dev ‚Üí prod to deploy



---

‚úÖ What You Don't Need

Since you're not separating environments physically:

No separate dev server required.

No SSH/rsync needed ‚Äî Jenkins agents handle it.

No system crons ‚Äî use Jenkins cron for logging and flexibility.



---

üîö Summary

Task	Recommendation

Dev/prod separation	Use branches + ENVIRONMENT var
Cron execution	Use Jenkins cron (cron('H/5 * * * *'))
Server type	All prod, but logic-based behavior
Deployment	Bitbucket push triggers Jenkins
Job execution	Jenkins matrix job on all agents



---

Would you like a complete main.py template showing how ENVIRONMENT toggles behavior and logs cleanly?

Absolutely! Let me walk you through the end-to-end setup for your automated, environment-aware job management system using Bitbucket, Jenkins, and your 4 production servers (as Jenkins agents).


---

‚úÖ High-Level Architecture

Bitbucket (dev/prod branches)
                       |
              +--------+---------+
              | Jenkins (CI/CD) |
              +--------+--------+
                       |
           Jenkins Matrix Job (Triggers Every 5 Min)
        /         |         |         \
    server1   server2   server3   server4 (Jenkins agents)
       |          |          |         |
    main.py (job rebalancer logic using ENVIRONMENT)


---

üîÑ Full Walkthrough: What Happens and When

üöÄ 1. You Push Code to Bitbucket

Your repo has two branches: dev and prod.

You push changes to either:

dev: for dry-run/test behavior

prod: for actual job-moving logic



Structure:

job-mover/
‚îú‚îÄ‚îÄ main.py
‚îú‚îÄ‚îÄ Jenkinsfile
‚îú‚îÄ‚îÄ config/dev.env (optional)
‚îú‚îÄ‚îÄ config/prod.env (optional)


---

‚öôÔ∏è 2. Jenkins Watches for Changes or Runs on a Schedule

You‚Äôve created a Jenkins multibranch pipeline job.

Jenkins:

Checks out the branch (dev or prod)

Sets ENVIRONMENT=dev or prod accordingly

Runs every 5 minutes via cron:

triggers {
    cron('H/5 * * * *')
}




---

üß† 3. Jenkinsfile Logic

environment {
    PYTHON_ENV = "${env.BRANCH_NAME == 'prod' ? 'prod' : 'dev'}"
}

For dev branch: PYTHON_ENV=dev

For prod branch: PYTHON_ENV=prod


Jenkins executes:

ENVIRONMENT=${PYTHON_ENV} python3 main.py

This injects the correct environment variable into your script.


---

üñ•Ô∏è 4. Jenkins Matrix Runs the Script on All 4 Servers

matrix {
  axes {
    axis {
      name 'NODE_LABEL'
      values 'server1', 'server2', 'server3', 'server4'
    }
  }
  agent { label NODE_LABEL }
}

Each node:

Checks out the repo

Executes the script with the right ENV

Shares the exact same logic (no manual file copies)



---

üßæ 5. main.py Behavior Based on ENVIRONMENT

In main.py:

import os
ENVIRONMENT = os.getenv("ENVIRONMENT", "dev")
IS_DRY_RUN = ENVIRONMENT == "dev"
print(f"Running in {ENVIRONMENT.upper()} mode.")

Then inside job-moving logic:

if IS_DRY_RUN:
    print(f"[DRY-RUN] Would move job {job['job_id']} to {target_queue}")
else:
    run_cmd(f"bmod -q {target_queue} {job['job_id']}")

So:

In dev: nothing is actually moved

In prod: real job movements happen



---

üíæ 6. Optional: History and Audit

You already have a record_job_move(...) function writing to JOB_MOVE_TO_FLEXI_HISTORY.

In dev, it can skip DB inserts (optional), or you can still log dry-run attempts if needed.


---

‚úÖ Summary: What Happens When You Push Code

Step	What Happens

1	You push to dev or prod branch in Bitbucket
2	Jenkins sees the change or triggers via cron
3	Jenkins checks out the repo on all 4 prod servers
4	Jenkins runs main.py with the right ENVIRONMENT
5	Script runs in dry-run (dev) or actual mode (prod)
6	Job logic executes dynamically per server
7	Audit, logging, and job movement are handled automatically



---

üõ†Ô∏è Want a Quick Start?

I can:

Build you a starter main.py with dev/prod awareness

Provide a full Jenkinsfile

Help you create a Jenkins multibranch job

Optional: .env config support


Let me know what you want to generate or build next.



